{
  "dependencies": [
    "@ai-sdk/openai",
    "ai"
  ],
  "files": [
    {
      "path": "app/api/ai/command/route.ts",
      "content": "import type { NextRequest } from 'next/server';\n\nimport { createOpenAI } from '@ai-sdk/openai';\nimport { convertToCoreMessages, smoothStream, streamText } from 'ai';\nimport { NextResponse } from 'next/server';\n\nconst CHUNKING_REGEXPS = {\n  line: /\\n+/m,\n  list: /.{8}/m,\n  word: /\\S+\\s+/m,\n};\n\nexport async function POST(req: NextRequest) {\n  const { apiKey: key, messages, model = 'gpt-4o', system } = await req.json();\n\n  const apiKey = key || process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return NextResponse.json(\n      { error: 'Missing OpenAI API key.' },\n      { status: 401 }\n    );\n  }\n\n  const openai = createOpenAI({ apiKey });\n\n  let isInCodeBlock = false;\n  let isInTable = false;\n  let isInList = false;\n  let isInLink = false;\n  try {\n    const result = streamText({\n      experimental_transform: smoothStream({\n        chunking: (buffer) => {\n          // Check for code block markers\n          if (buffer.includes('```')) {\n            isInCodeBlock = !isInCodeBlock;\n          }\n\n          // test case: should not deserialize link with markdown syntax\n          if (buffer.includes('http')) {\n            isInLink = true;\n          } else if (buffer.includes('https')) {\n            isInLink = true;\n          } else if (buffer.includes('\\n') && isInLink) {\n            isInLink = false;\n          }\n\n          if (buffer.includes('*') || buffer.includes('-')) {\n            isInList = true;\n          } else if (buffer.includes('\\n') && isInList) {\n            isInList = false;\n          }\n\n          // Simple table detection: enter on |, exit on double newline\n          if (!isInTable && buffer.includes('|')) {\n            isInTable = true;\n          } else if (isInTable && buffer.includes('\\n\\n')) {\n            isInTable = false;\n          }\n\n          // Use line chunking for code blocks and tables, word chunking otherwise\n          // Choose the appropriate chunking strategy based on content type\n          let match;\n\n          if (isInCodeBlock || isInTable || isInLink) {\n            // Use line chunking for code blocks and tables\n            match = CHUNKING_REGEXPS.line.exec(buffer);\n          } else if (isInList) {\n            // Use list chunking for lists\n            match = CHUNKING_REGEXPS.list.exec(buffer);\n          } else {\n            // Use word chunking for regular text\n            match = CHUNKING_REGEXPS.word.exec(buffer);\n          }\n\n          if (!match) {\n            return null;\n          }\n\n          return buffer.slice(0, match.index) + match?.[0];\n        },\n      }),\n      maxTokens: 2048,\n      messages: convertToCoreMessages(messages),\n      model: openai('gpt-4o'),\n      system: system,\n    });\n\n    return result.toDataStreamResponse();\n  } catch {\n    return NextResponse.json(\n      { error: 'Failed to process AI request' },\n      { status: 500 }\n    );\n  }\n}\n",
      "type": "registry:lib",
      "target": "app/api/ai/command/route.ts"
    },
    {
      "path": "app/api/ai/copilot/route.ts",
      "content": "import type { NextRequest } from 'next/server';\n\nimport { createOpenAI } from '@ai-sdk/openai';\nimport { generateText } from 'ai';\nimport { NextResponse } from 'next/server';\n\nexport async function POST(req: NextRequest) {\n  const {\n    apiKey: key,\n    model = 'gpt-4o-mini',\n    prompt,\n    system,\n  } = await req.json();\n\n  const apiKey = key || process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return NextResponse.json(\n      { error: 'Missing OpenAI API key.' },\n      { status: 401 }\n    );\n  }\n\n  const openai = createOpenAI({ apiKey });\n\n  try {\n    const result = await generateText({\n      abortSignal: req.signal,\n      maxTokens: 50,\n      model: openai(model),\n      prompt: prompt,\n      system,\n      temperature: 0.7,\n    });\n\n    return NextResponse.json(result);\n  } catch (error: any) {\n    if (error.name === 'AbortError') {\n      return NextResponse.json(null, { status: 408 });\n    }\n\n    return NextResponse.json(\n      { error: 'Failed to process AI request' },\n      { status: 500 }\n    );\n  }\n}\n",
      "type": "registry:lib",
      "target": "app/api/ai/copilot/route.ts"
    }
  ],
  "name": "api-ai",
  "registryDependencies": [],
  "type": "registry:lib",
  "$schema": "https://platejs.org/schema/registry-item.json",
  "author": "udecode (https://platejs.org)"
}